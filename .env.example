# LM Studio (OpenAI-compatible) defaults
LMSTUDIO_BASE_URL=http://127.0.0.1:1234/v1
LMSTUDIO_API_KEY=lm-studio
# Default LM Studio model (change per environment)
LMSTUDIO_MODEL=lmstudio-community/gpt-oss-20b
#LMSTUDIO_MODEL=Qwen/Qwen3-VL-4B
#LMSTUDIO_MODEL=SarashinaAI/Sarashina2.2-Vision-3B

# Toggle/interval for calling the VLM from StreamingSensorState
USE_VLM=false
VLM_INTERVAL_SECONDS=15

# Optional: custom OpenAI-compatible endpoint (self-hosted or cloud)
# When set, this takes precedence over LM Studio.
# Examples:
#   OPENAI_BASE_URL=http://localhost:8000/v1
#   OPENAI_API_KEY=sk-your-key
#   OPENAI_MODEL=your-local-model-name
OPENAI_BASE_URL=
OPENAI_API_KEY=
OPENAI_MODEL=

# Optional comma-separated preference order when auto-picking a model
# e.g. "gpt-oss-20b,Qwen,Deepseek"
LLM_MODEL_PREFER=Qwen,gemma,Llama,Phi,Nous,Deepseek
